# OCTA500 6M 데이터셋 - Flow Matching (MedSegDiff backbone, SAUNA soft label, VLM-FiLM + Junction Gating)
model:
  arch_name: medsegdiff_flow
  mode: dfm_binary
  dfm_sampler: euler   # 또는 heun
  dfm_eps: 1e-6
  debug_dfm: false

  use_vlm_film: false
  vlm_film_decoder_stages: [2, 3]  # 후반 2개 스테이지 (64ch, 32ch)에만 적용
  vlm_film_config:
    model_name: "Qwen/Qwen2.5-VL-3B-Instruct"
    cond_dim: 256
    cache_dir: "cache/vlm_profiles"
    batch_strategy: "per_sample"  # CRITICAL: per-sample conditioning (not "first")
    update_interval_steps_train: 25  # ~1 epoch for typical dataset sizes
    update_interval_steps_eval: 1    # Always fresh in validation
    # FiLM parameters (deprecated - using unconstrained γ=1+Linear(c), β=Linear(c))
    gamma_scale: 0.1  # Not used: identity-init allows unbounded learning
    beta_scale: 0.1   # Not used: identity-init allows unbounded learning
    cond_layernorm: true  # Not used: removed from new implementation
    film_debug_enabled: true
    film_debug_every_n_steps_train: 50
    film_debug_every_n_steps_val: 20
  
  # Junction-aware FiLM gating (topology safety gate)
  # Controls spatial application of VLM-FiLM modulation to reduce false positives at vessel junctions
  junction_gating_config:
    enabled: true                    
    warmup_epochs: 5  # Apply after initial convergence
    source: "pred"               
    threshold: 0.5               
    degree_threshold: 2  # Detect T-junctions and Y-junctions
    radius_px: 8               
    gate_value_in_junction: 0.0    
    apply_stages: "same_as_film"    
    interp: "nearest"              

  image_size: 224
  patch_plan:
    - [224, 1]
  dim: 32
  timesteps: 50
  num_ensemble: 5
  sigma: 0.25
  use_sliding_infer: true
  learning_rate: 0.0002
  weight_decay: 0.00001
  use_ema: true
  ema_decay: 0.9999
  num_classes: 2
  experiment_name: flow_model_medsegdiff
  data_name: octa500_6m
  log_image_enabled: false
  log_image_names:
    - '10181.bmp'
    - '10185.bmp'
    - '10190.bmp'
  # UNet architecture parameters (mapped to MedSegDiff backbone)
  # model_channels must be divisible by 8 (GroupNorm requirement)
  # Reduced to ~14M params (similar to berdiff) for fair comparison
  model_channels: 32
  channel_mult: [1, 2, 3, 4]
  channel_mult_emb: 4
  num_blocks: 3
  # Match attention to VLM-FiLM stages only (s2=56x56, s3=28x28 for 224 input)
  attn_resolutions: [56, 28]
  dropout: 0.0
  label_dim: 0
  augment_dim: 0
  use_gradient_checkpointing: true

  loss:
    name: flow_matching
    params:
      scheme: l2

data:
  name: octa500_6m
  train_dir: data/OCTA500_6M/train
  val_dir: data/OCTA500_6M/val
  test_dir: data/OCTA500_6M/test
  train_bs: 6
  image_size: 224
  num_samples_per_image: 16
  use_sauna_transform: false

trainer:
  max_epochs: 500
  accelerator: gpu
  devices: 1
  precision: 16-mixed
  enable_progress_bar: true
  check_val_every_n_epoch: 15
  accumulate_grad_batches: 8  # 실효 배치: 6 × 8 = 48
  log_every_n_steps: 10
  gradient_clip_val: 1.0
