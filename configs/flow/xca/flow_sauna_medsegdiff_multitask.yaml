# XCA 데이터셋 - Flow Matching (MedSegDiff multitask backbone, SAUNA soft label)
model:
  arch_name: medsegdiff_flow_multitask
  image_size: 320
  patch_plan:
    - [320, 1]
  dim: 32
  timesteps: 50
  num_ensemble: 1
  sigma: 0.25
  use_sliding_infer: true
  learning_rate: 0.0002
  weight_decay: 0.00001
  use_ema: true
  ema_decay: 0.9999
  num_classes: 2
  experiment_name: flow_model_medsegdiff_multitask
  data_name: xca
  log_image_enabled: true
  log_image_names:
    - '0000.png'
    - '0010.png'
    - '0019.png'
  # UNet architecture parameters (mapped to MedSegDiff backbone)
  # model_channels must be divisible by 8 (GroupNorm requirement)
  # Reduced to ~14M params (similar to berdiff) for fair comparison
  model_channels: 32
  channel_mult: [1, 2, 3, 4]
  channel_mult_emb: 4
  num_blocks: 3
  # Match attention to actual feature map resolutions: 320 -> 160 -> 80 -> 40
  attn_resolutions: [80, 40]
  dropout: 0.0
  label_dim: 0
  augment_dim: 0

  loss:
    name: flow_matching
    params:
      scheme: l2
  # Soft branch weight: loss = loss_hard + lambda_soft * loss_soft
  lambda_soft: 0.1

data:
  name: xca
  train_dir: data/xca_full/train
  val_dir: data/xca_full/val
  test_dir: data/xca_full/test
  train_bs: 6  # DDP: 각 GPU당 1 → 총 6 GPU × 1 = 6
  image_size: 320
  num_samples_per_image: 16  # 메모리 최적화
  use_sauna_transform: true 

trainer:
  max_epochs: 500
  accelerator: gpu
  devices: 1
  precision: 32-true
  enable_progress_bar: true
  check_val_every_n_epoch: 10
  accumulate_grad_batches: 8  # 실효 배치: 6 GPU × 1 × 8 = 48
  log_every_n_steps: 10
  gradient_clip_val: 1.0
